---
title: "Convolutional Neural Network (CNN) Architecture and Hyper-Parameter Optimization (HPO) for Image Classification"
collection: publications
permalink: /publication/cnn-hpo
excerpt: "Deep learning has transformed the field of computer vision, with CNNs becoming the foundation for a wide range of image classification tasks. Their ability to automatically learn hierarchical feature representations has made them indispensable in domains such as healthcare, autonomous systems, and industrial automation. However, achieving optimal performance with CNNs depends heavily on selecting appropriate hyperparameters—such as architectural configurations—which significantly influence training efficiency and generalization capability.Hyperparameter optimization (HPO) is a crucial yet challenging task due to the highdimensional and non-convex nature of the search space. Traditional methods like grid search and random search, while straightforward, suffer from inefficiency and excessive computational costs. More advanced approaches, including Bayesian optimization, evolutionary algorithms, and local search techniques, have been developed to explore the search space more effectively. Each method presents advantages and limitations, with trade-offs between exploration and exploitation, computational feasibility, and scalability."
date: June 2025
Status: 'Preprint' 
paperurl: 'https://www.researchgate.net/publication/396464806_Stochastic_Best_Improvement_with_Progressive_Halving_Hyperparameter_Optimization_for_Image_Classification?channel=doi&linkId=68ee334a7d9a4d4e87097244&showFulltext=true'

citation: 'Aboud, I., Akeb, A., Baghdadi, M. M., Brouthen, K., & Seghairi, A. (2025). Stochastic Best Improvement with Progressive Halving Hyperparameter Optimization for Image Classification [Preprint].'
---
Deep learning has transformed the field of computer vision, with CNNs becoming the foundation for a wide range of image classification tasks. Their ability to automatically learn hierarchical feature representations has made them indispensable in domains such as healthcare, autonomous systems, and industrial automation. However, achieving optimal performance with CNNs depends heavily on selecting appropriate hyperparameters—such as architectural configurations—which significantly influence training efficiency and generalization capability.Hyperparameter optimization (HPO) is a crucial yet challenging task due to the highdimensional and non-convex nature of the search space. Traditional methods like grid search and random search, while straightforward, suffer from inefficiency and excessive computational costs. More advanced approaches, including Bayesian optimization, evolutionary algorithms, and local search techniques, have been developed to explore the search space more effectively. Each method presents advantages and limitations, with trade-offs between exploration and exploitation, computational feasibility, and scalability.
The code is publicly available at [this http URL](https://github.com/BrouthenKamel/Local-Search-HPO-in-CNNs).

[Download paper here](https://www.researchgate.net/publication/396464806_Stochastic_Best_Improvement_with_Progressive_Halving_Hyperparameter_Optimization_for_Image_Classification?channel=doi&linkId=68ee334a7d9a4d4e87097244&showFulltext=true)

Recommended citation: Aboud, I., Akeb, A., Baghdadi, M. M., Brouthen, K., & Seghairi, A. (2025). Stochastic Best Improvement with Progressive Halving Hyperparameter Optimization for Image Classification [Preprint].